# /ws/drowsiness/landmarks/{session_id} ìˆ˜ì • ì½”ë“œ

from fastapi import APIRouter, WebSocket, WebSocketDisconnect
import os, pandas as pd, json, traceback
import itertools

websocket_router = APIRouter()

@websocket_router.websocket("/ws/drowsiness/landmarks/{session_id}")
async def websocket_landmarks(websocket: WebSocket, session_id: str):
    await websocket.accept()
    base_dir    = os.path.abspath(os.path.join(os.path.dirname(__file__),
                                               "../../../drowsiness_data"))
    session_dir = os.path.join(base_dir, session_id)
    os.makedirs(session_dir, exist_ok=True)

    all_rows = []
    # ì•½ 10ì´ˆ ë¶„ëŸ‰(30fps ê¸°ì¤€ 300 í”„ë ˆì„)ì„ í•˜ë‚˜ì˜ ì²­í¬ë¡œ ì„¤ì •
    chunk_size = 150

    # --- ğŸ‘‡ í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ (1) ---
    # íŒŒì¼ ë²ˆí˜¸ì™€ í˜„ì¬ íŒŒì¼ì— ì €ì¥ëœ ì²­í¬ ìˆ˜ë¥¼ ì¶”ì í•˜ëŠ” ë³€ìˆ˜ ì¶”ê°€
    file_index = 1
    chunk_count = 0
    # íŒŒì¼ í•˜ë‚˜ë‹¹ 30ê°œì˜ ì²­í¬ë¥¼ ì €ì¥ (300 í”„ë ˆì„/ì²­í¬ * 30 ì²­í¬ = 9000 í”„ë ˆì„ â‰ˆ 5ë¶„)
    chunks_per_file = 60

    # ì²« ë²ˆì§¸ íŒŒì¼ ê²½ë¡œë¥¼ ìƒì„±
    csv_path = os.path.join(session_dir, f"landmarks_{file_index:03}.csv")
    print(f"ğŸ“‚ Start saving to: {csv_path}")
    # --- ğŸ‘† í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ (1) ---

    try:
        while True:
            data = await websocket.receive_text()
            try:
                msg = json.loads(data)
            except json.JSONDecodeError:
                print(f"âš ï¸  JSON decode fail â†’ {data[:50]}...")
                continue

            if msg.get("type") == "ping" or "frame" not in msg:
                continue

            timestamp = msg["timestamp"]
            landmarks = msg["frame"]

            flattened_landmarks = list(itertools.chain.from_iterable(landmarks))
            all_rows.append([timestamp] + flattened_landmarks)

            # ë©”ëª¨ë¦¬ ë²„í¼(all_rows)ê°€ ê°€ë“ ì°¨ë©´ íŒŒì¼ì— ì¶”ê°€í•©ë‹ˆë‹¤.
            if len(all_rows) >= chunk_size:
                df = pd.DataFrame(all_rows)
                df.to_csv(csv_path, mode='a', header=False, index=False)

                print(f"âœ… Appended {len(all_rows)} rows to {os.path.basename(csv_path)}")
                all_rows.clear()  # ë²„í¼ ë¹„ìš°ê¸°

                # --- ğŸ‘‡ í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ (2) ---
                chunk_count += 1 # í˜„ì¬ íŒŒì¼ì— ì²­í¬ê°€ í•˜ë‚˜ ë” ì €ì¥ë˜ì—ˆìŒì„ ê¸°ë¡

                # í˜„ì¬ íŒŒì¼ì— ì €ì¥ëœ ì²­í¬ ìˆ˜ê°€ 5ë¶„ ë¶„ëŸ‰(30ê°œ)ì— ë„ë‹¬í•˜ë©´
                if chunk_count >= chunks_per_file:
                    file_index += 1 # ë‹¤ìŒ íŒŒì¼ ë²ˆí˜¸ë¡œ ì¦ê°€
                    chunk_count = 0 # ì²­í¬ ì¹´ìš´í„° ì´ˆê¸°í™”
                    # ìƒˆ íŒŒì¼ ê²½ë¡œ ìƒì„±
                    csv_path = os.path.join(session_dir, f"landmarks_{file_index:03}.csv")
                    print(f"ğŸ”„ Switched to new file: {csv_path}")
                # --- ğŸ‘† í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ (2) ---

    except WebSocketDisconnect:
        print(f"ğŸ”Œ disconnect [{session_id}]")
    except Exception:
        print("â— unexpected error")
        traceback.print_exc()
    finally:
        # ì—°ê²°ì´ ëŠì–´ì§€ê¸° ì§ì „, ë²„í¼ì— ë‚¨ì•„ìˆëŠ” ë°ì´í„°ë¥¼ ë§ˆì§€ë§‰ íŒŒì¼ì— ë§ˆì € ì €ì¥í•©ë‹ˆë‹¤.
        if all_rows:
            df = pd.DataFrame(all_rows)
            df.to_csv(csv_path, mode='a', header=False, index=False)
            print(f"âœ… Appended final {len(all_rows)} rows to {os.path.basename(csv_path)}")