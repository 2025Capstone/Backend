import glob
import time
import uuid
import random
import os

# --- FastAPI ---
from fastapi import APIRouter, Depends, Body, UploadFile, File, HTTPException

# --- ë°ì´í„°ë² ì´ìŠ¤ ë° ì¸ì¦ ---
from sqlalchemy.orm import Session
from sqlalchemy import func
from app.dependencies.db import get_db
from app.dependencies.auth import get_current_student_uid
from app.services.auth_service import get_current_student

# --- Firebase Admin SDK ---
import firebase_admin

# --- ìŠ¤í‚¤ë§ˆ (Schemas) ---
from app.schemas.drowsiness import (
    DrowsinessStartRequest, DrowsinessStartResponse,
    DrowsinessVerifyRequest, DrowsinessVerifyResponse,
    DrowsinessFinishRequest, DrowsinessFinishResponse, DrowsinessPrediction
)
from app.schemas.lecture import LectureListResponse
from app.schemas.student import (
    LectureVideoListRequest, LectureVideoListResponse,
    VideoLinkRequest, VideoLinkResponse,
    StudentProfileResponse,
    StudentNameUpdateRequest, StudentNameUpdateResponse,
    EnrollmentCancelRequest, EnrollmentCancelResponse, EnrollmentResponse, EnrollmentRequest,
    VideoProgressUpdateRequest, VideoProgressUpdateResponse
)

# --- ëª¨ë¸ (Database Models) ---
from app.models.instructor import Instructor
from app.models.lecture import Lecture
from app.models.video import Video
from app.models.enrollment import Enrollment
from app.models.watch_history import WatchHistory
from app.models.student import Student
from app.models.drowsiness_level import DrowsinessLevel
from app.services.hrv_analyzer import compute_hrv_and_features_from_firebase

# --- ì„œë¹„ìŠ¤ (Business Logic) ---
from app.services.student import (
    get_enrolled_lectures_for_student, get_lecture_videos_for_student, get_video_link_for_student, get_student_profile,
    update_student_name, cancel_enrollment, enroll_student_in_lecture, upload_profile_image_to_s3
)

# --- ë¨¸ì‹ ëŸ¬ë‹ ë° ë°ì´í„° ì²˜ë¦¬ ---
import pandas as pd
import torch
from app.utils.drowsiness_data_utils import make_shard_and_pt
from app.ml.data_loader import SessionSequenceDataset
from app.ml.pipeline import MultimodalFatigueModel

# APIRouterì—ì„œ ì „ì—­ dependencies ì œê±°
router = APIRouter()


# =========================
# í•™ìƒ ê°•ì˜ ê´€ë ¨ API (ê°œë³„ ì¸ì¦ ì¶”ê°€)
# =========================

@router.get("/lecture", summary="ë‚´ ìˆ˜ê°•ì‹ ì²­ ê°•ì˜ ëª©ë¡", dependencies=[Depends(get_current_student)])
def get_my_enrolled_lectures(
        db: Session = Depends(get_db),
        student_uid: str = Depends(get_current_student_uid)
):
    lectures = get_enrolled_lectures_for_student(db, student_uid)
    return {"lectures": lectures}


@router.post("/lecture/video", response_model=LectureVideoListResponse, summary="íŠ¹ì • ê°•ì˜ì˜ ì˜ìƒ ëª©ë¡ ì¡°íšŒ",
             dependencies=[Depends(get_current_student)])
def get_lecture_video_list(
        req: LectureVideoListRequest = Body(...),
        db: Session = Depends(get_db),
        student_uid: str = Depends(get_current_student_uid)
):
    videos = get_lecture_videos_for_student(db, student_uid, req.lecture_id)
    return LectureVideoListResponse(videos=videos)


@router.post("/lecture/video/link", response_model=VideoLinkResponse, summary="íŠ¹ì • ì˜ìƒì˜ S3 ë§í¬ ì œê³µ",
             dependencies=[Depends(get_current_student)])
def get_video_s3_link(
        req: VideoLinkRequest = Body(...),
        db: Session = Depends(get_db),
        student_uid: str = Depends(get_current_student_uid)
):
    return get_video_link_for_student(db, student_uid, req.video_id)


@router.get("/profile", response_model=StudentProfileResponse, summary="ë‚´ í”„ë¡œí•„ ì •ë³´ ì¡°íšŒ",
            dependencies=[Depends(get_current_student)])
def get_my_profile(
        db: Session = Depends(get_db),
        student_uid: str = Depends(get_current_student_uid)
):
    return get_student_profile(db, student_uid)


@router.patch("/profile/name", response_model=StudentNameUpdateResponse, summary="í•™ìƒ ì´ë¦„ ë³€ê²½",
              dependencies=[Depends(get_current_student)])
def set_my_name(
        req: StudentNameUpdateRequest = Body(...),
        db: Session = Depends(get_db),
        student_uid: str = Depends(get_current_student_uid)
):
    return update_student_name(db, student_uid, req.name)


@router.post("/lecture/video/progress", response_model=VideoProgressUpdateResponse, summary="ì˜ìƒ ì§„ì²™ë„ ê¸°ë¡",
             dependencies=[Depends(get_current_student)])
def update_video_progress(
        req: VideoProgressUpdateRequest = Body(...),
        db: Session = Depends(get_db),
        student_uid: str = Depends(get_current_student_uid)
):
    video = db.query(Video).filter(Video.id == req.video_id, Video.is_public == 1).first()
    if not video:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ì˜ìƒì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ë¹„ê³µê°œ ìƒíƒœì…ë‹ˆë‹¤.")
    enrollment = db.query(Enrollment).filter(
        Enrollment.student_uid == student_uid,
        Enrollment.lecture_id == video.lecture_id
    ).first()
    if not enrollment:
        raise HTTPException(status_code=403, detail="í•´ë‹¹ ê°•ì˜ì— ìˆ˜ê°•ì‹ ì²­ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    history = db.query(WatchHistory).filter(
        WatchHistory.student_uid == student_uid,
        WatchHistory.video_id == req.video_id
    ).first()
    if history:
        history.timestamp = func.now()
        history.watched_percent = max(getattr(history, 'watched_percent', 0), req.watched_percent)
    else:
        history = WatchHistory(
            student_uid=student_uid,
            video_id=req.video_id,
            timestamp=func.now(),
            watched_percent=req.watched_percent
        )
        db.add(history)
    db.commit()
    return VideoProgressUpdateResponse(message="ì§„ì²™ë„ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


@router.post("/profile/image", summary="í”„ë¡œí•„ ì‚¬ì§„ ì—…ë¡œë“œ ë° ì €ì¥", dependencies=[Depends(get_current_student)])
def upload_my_profile_image(
        file: UploadFile = File(...),
        db: Session = Depends(get_db),
        student_uid: str = Depends(get_current_student_uid)
):
    s3_url = upload_profile_image_to_s3(file)
    student = db.query(Student).filter(Student.uid == student_uid).first()
    if not student:
        raise HTTPException(status_code=404, detail="í•™ìƒ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    student.profile_image_url = s3_url
    db.commit()
    db.refresh(student)
    return {"profile_image_url": s3_url}


@router.get("/recent-incomplete-videos", summary="ìµœê·¼ ì‹œì²­ê¸°ë¡ ì¤‘ ë¯¸ì™„ë£Œ ì˜ìƒ 10ê°œ ì¡°íšŒ", dependencies=[Depends(get_current_student)])
def get_recent_incomplete_videos(
        db: Session = Depends(get_db),
        student_uid: str = Depends(get_current_student_uid)
):
    results = (
        db.query(
            WatchHistory.video_id,
            Video.lecture_id,
            Lecture.name.label("lecture_name"),
            Video.title.label("video_name"),
            Instructor.name.label("instructor_name"),
            WatchHistory.timestamp,
            Video.video_image_url
        )
        .join(Video, WatchHistory.video_id == Video.id)
        .join(Lecture, Video.lecture_id == Lecture.id)
        .join(Instructor, Lecture.instructor_id == Instructor.id)
        .filter(WatchHistory.student_uid == student_uid)
        .filter(WatchHistory.watched_percent < 95)
        .order_by(WatchHistory.timestamp.desc())
        .limit(10)
        .all()
    )
    return [
        {
            "video_id": row.video_id,
            "lecture_id": row.lecture_id,
            "lecture_name": row.lecture_name,
            "video_name": row.video_name,
            "instructor_name": row.instructor_name,
            "timestamp": row.timestamp,
            "video_image_url": row.video_image_url
        }
        for row in results
    ]


# =========================
# ì¡¸ìŒ íƒì§€ í”Œë¡œìš° API
# =========================

@router.post("/drowsiness/start", response_model=DrowsinessStartResponse, summary="ì¡¸ìŒ íƒì§€ ì„¸ì…˜ ì‹œì‘",
             dependencies=[Depends(get_current_student)])
def start_drowsiness_detection(
        req: DrowsinessStartRequest = Body(...),
        student_uid: str = Depends(get_current_student_uid)
):
    """
    ì¡¸ìŒ íƒì§€ ì„¸ì…˜ì„ ì‹œì‘í•˜ê³ , Firebaseì— ì„¸ì…˜ ë°ì´í„°ì™€ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ìƒì„±ëœ 6ìë¦¬ ì¸ì¦ì½”ë“œë¥¼ í´ë¼ì´ì–¸íŠ¸ì— ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    session_id = str(uuid.uuid4())
    auth_code = f"{random.randint(0, 999999):06d}"

    try:
        from firebase_admin import db

        ref = db.reference(f"{session_id}")
        ref.set({
            "pairing": {
                "paired": False,
                "stop": False,
                "auth_code": auth_code,
                "student_uid": student_uid,
                "video_id": req.video_id
            },
            "PPG_Data": {}
        })

        index_ref = db.reference(f"auth_code_index/{auth_code}")
        index_ref.set(session_id)

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Firebase ì„¸ì…˜ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

    return DrowsinessStartResponse(session_id=session_id, auth_code=auth_code,
                                   message="ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì›¨ì–´ëŸ¬ë¸”ì— ì¸ì¦ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")


@router.post("/drowsiness/verify", response_model=DrowsinessVerifyResponse, summary="[ì›¨ì–´ëŸ¬ë¸”ìš©] ì¸ì¦ì½”ë“œë¡œ ê²€ì¦")
def verify_drowsiness_from_wearable(
        req: DrowsinessVerifyRequest,
):
    """
    ì›¨ì–´ëŸ¬ë¸” ê¸°ê¸°ì—ì„œ ì „ì†¡í•œ ì¸ì¦ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ì„ ì°¾ì•„ ì—°ë™í•˜ê³ , ì„¸ì…˜ IDë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì´ APIëŠ” ë¡œê·¸ì¸ í† í°ì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤.
    """
    try:
        from firebase_admin import db

        index_ref = db.reference(f"auth_code_index/{req.code}")
        session_id = index_ref.get()

        if not session_id:
            raise HTTPException(status_code=404, detail="ì¸ì¦ì½”ë“œê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

        session_ref = db.reference(f"{session_id}/pairing")
        session_data = session_ref.get()

        if not session_data:
            raise HTTPException(status_code=404, detail="ì¸ë±ìŠ¤ëŠ” ì¡´ì¬í•˜ì§€ë§Œ, í•´ë‹¹ ì„¸ì…˜ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        session_ref.update({"paired": True})

        index_ref.delete()

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Firebase ë°ì´í„° ê²€ì¦/ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    return DrowsinessVerifyResponse(session_id=session_id, verified=True, message="ì›¨ì–´ëŸ¬ë¸” ì—°ë™ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


@router.post("/drowsiness/finish", response_model=DrowsinessFinishResponse, summary="ì¡¸ìŒ íƒì§€ ì„¸ì…˜ ì¢…ë£Œ ë° ë¶„ì„",
             dependencies=[Depends(get_current_student)])
def finish_drowsiness_detection(
        req: DrowsinessFinishRequest,
        student_uid: str = Depends(get_current_student_uid),
        db_session: Session = Depends(get_db)
):
    session_id = req.session_id
    base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../drowsiness_data'))
    session_dir = os.path.join(base_dir, session_id)

    from firebase_admin import db as firebase_db

    try:
        session_ref = firebase_db.reference(f"{session_id}")
        pairing_ref = session_ref.child("pairing")
        pairing_data = pairing_ref.get()
        if not pairing_data:
            raise HTTPException(status_code=404, detail="ì„¸ì…˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        if pairing_data.get("student_uid") != student_uid:
            raise HTTPException(status_code=403, detail="ë³¸ì¸ì˜ ì„¸ì…˜ì´ ì•„ë‹™ë‹ˆë‹¤.")
        pairing_ref.update({"stop": True})
        video_id = pairing_data.get("video_id")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Firebase ì„¸ì…˜ ì¢…ë£Œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # --- 1.5. ì¤‘ë³µ ë¶„ì„ ë°©ì§€: ì´ë¯¸ ë¶„ì„ëœ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸ ---
    print(f"[{session_id}] ğŸ” ì¤‘ë³µ ë¶„ì„ í™•ì¸ ì¤‘...")
    existing_analysis = db_session.query(DrowsinessLevel).filter(
        DrowsinessLevel.video_id == video_id,
        DrowsinessLevel.student_uid == student_uid
    ).first()
    
    if existing_analysis:
        print(f"[{session_id}] âš ï¸ ì´ë¯¸ ë¶„ì„ ì™„ë£Œëœ ë°ì´í„° ë°œê²¬")
        raise HTTPException(
            status_code=409,  # 409 Conflict
            detail=f"í•´ë‹¹ ì˜ìƒ(video_id={video_id})ì— ëŒ€í•œ ì¡¸ìŒ ë¶„ì„ì´ ì´ë¯¸ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì¤‘ë³µ ë¶„ì„ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ìš”ì²­ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤."
        )
    print(f"[{session_id}] âœ… ì¤‘ë³µ ë¶„ì„ í™•ì¸ ì™„ë£Œ (ë¶„ì„ ì´ë ¥ ì—†ìŒ)")

    # --- 2. PPG ë°ì´í„° ìˆ˜ì‹  ì™„ë£Œ ëŒ€ê¸° (Polling) ---
    try:
        polling_timeout = 180  # ìµœëŒ€ 3ë¶„ ëŒ€ê¸°
        polling_interval = 5   # 5ì´ˆ ê°„ê²©ìœ¼ë¡œ í™•ì¸
        stability_threshold = 10 # 10ì´ˆ ë™ì•ˆ ë°ì´í„° ê°œìˆ˜ ë³€í™” ì—†ìœ¼ë©´ ì™„ë£Œë¡œ ê°„ì£¼

        last_data_count = -1
        stable_time = 0
        waited_time = 0

        while waited_time < polling_timeout:
            ppg_node = session_ref.child("PPG_Data").get() or {}
            current_data_count = len(ppg_node)

            if current_data_count > last_data_count:
                # ë°ì´í„°ê°€ ì—¬ì „íˆ ìˆ˜ì‹  ì¤‘
                last_data_count = current_data_count
                stable_time = 0
            elif last_data_count > 0:
                # ë°ì´í„° ê°œìˆ˜ ë³€í™” ì—†ìŒ
                stable_time += polling_interval

            if stable_time >= stability_threshold:
                # ì—…ë¡œë“œê°€ ì•ˆì •í™”ë˜ì—ˆìœ¼ë¯€ë¡œ ì™„ë£Œë¡œ íŒë‹¨
                print(f"âœ… PPG ë°ì´í„° ìˆ˜ì‹  ì™„ë£Œ. (ì´ {current_data_count}ê°œ)")
                break

            time.sleep(polling_interval)
            waited_time += polling_interval
        else:
            # íƒ€ì„ì•„ì›ƒ ë°œìƒ
            raise HTTPException(status_code=504, detail="PPG ë°ì´í„° ìˆ˜ì‹  ëŒ€ê¸° ì‹œê°„ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")

    except HTTPException as e:
        raise e # íƒ€ì„ì•„ì›ƒ ì˜ˆì™¸ëŠ” ê·¸ëŒ€ë¡œ ì „ë‹¬
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"PPG ë°ì´í„° ìˆ˜ì‹  í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


    # --- 3. ì›¨ì–´ëŸ¬ë¸” íŠ¹ì§•(HRV) ë°ì´í„° ìƒì„± ---
    try:
        df_wearable = compute_hrv_and_features_from_firebase(session_id)
        # ë¶„ì„ ê²°ê³¼ë¥¼ ë””ë²„ê¹…ìš©ìœ¼ë¡œ ì €ì¥ (ì„ íƒ ì‚¬í•­)
        os.makedirs(session_dir, exist_ok=True)
        wearable_csv_path = os.path.join(session_dir, 'wearable_features.csv')
        df_wearable.to_csv(wearable_csv_path, index=False)
    except ValueError as e:
        raise HTTPException(status_code=400, detail=f"HRV ë¶„ì„ ì‹¤íŒ¨: {e}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"HRV ë¶„ì„ ì¤‘ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # --- 4. ëœë“œë§ˆí¬ ë°ì´í„° ë¡œë“œ (íŒŒì¼ ì“°ê¸° ì™„ë£Œ ëŒ€ê¸° í¬í•¨) ---
    print(f"[{session_id}] ğŸ“‚ Step 4: ëœë“œë§ˆí¬ ë°ì´í„° ë¡œë“œ ì‹œì‘")
    if not os.path.isdir(session_dir):
        raise HTTPException(status_code=404, detail="Landmark ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # WebSocketì„ í†µí•œ íŒŒì¼ ì“°ê¸°ê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 2ë¶„)
    print(f"[{session_id}] â³ ëœë“œë§ˆí¬ íŒŒì¼ ì“°ê¸° ì™„ë£Œ ëŒ€ê¸° ì¤‘...")
    timeout, interval, waited = 120, 1, 0
    while waited < timeout:
        landmark_files = glob.glob(os.path.join(session_dir, 'landmarks_*.csv'))
        if not landmark_files:  # íŒŒì¼ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ëŒ€ê¸°
            if waited % 10 == 0:  # 10ì´ˆë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥
                print(f"[{session_id}] â³ ëœë“œë§ˆí¬ íŒŒì¼ ëŒ€ê¸° ì¤‘... ({waited}ì´ˆ ê²½ê³¼)")
            time.sleep(interval)
            waited += interval
            continue

        last_modified = max(os.path.getmtime(f) for f in landmark_files)
        # ë§ˆì§€ë§‰ íŒŒì¼ ìˆ˜ì • í›„ 2ì´ˆ ì´ìƒ ì§€ë‚¬ìœ¼ë©´ ì“°ê¸°ê°€ ì™„ë£Œëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
        if time.time() - last_modified >= 2:
            print(f"[{session_id}] âœ… ëœë“œë§ˆí¬ íŒŒì¼ ì“°ê¸° ì™„ë£Œ í™•ì¸ (ì´ {len(landmark_files)}ê°œ íŒŒì¼)")
            break
        time.sleep(interval)
        waited += interval
    else:
        raise HTTPException(status_code=500, detail="Landmark ë°ì´í„° ì €ì¥ ëŒ€ê¸° ì‹œê°„ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")

    # ëœë“œë§ˆí¬ íŒŒì¼ ê°œìˆ˜ í™•ì¸ (ë³‘í•©ì€ PT íŒŒì¼ ìƒì„± ì‹œ ìë™ìœ¼ë¡œ ìˆ˜í–‰ë¨)
    print(f"[{session_id}] âœ… ëœë“œë§ˆí¬ ë°ì´í„° í™•ì¸ ì™„ë£Œ (ì´ {len(landmark_files)}ê°œ íŒŒì¼)")
    
    # --- 5. ë°ì´í„° ê²€ì¦ ---
    print(f"[{session_id}] âœ… Step 5: ë°ì´í„° ê²€ì¦ ì™„ë£Œ")
    print(f"[{session_id}] ğŸ“Š HRV ì„¸ê·¸ë¨¼íŠ¸: {len(df_wearable)}ê°œ (2ë¶„ ë‹¨ìœ„)")
    print(f"[{session_id}] ğŸ“Š ëœë“œë§ˆí¬ íŒŒì¼: {len(landmark_files)}ê°œ")
    
    # HRV íŠ¹ì§• ì°¨ì› í™•ì¸
    num_hrv_features = len([col for col in df_wearable.columns if col != 'timestamp'])
    print(f"[{session_id}] ğŸ“Š HRV íŠ¹ì§• ì°¨ì›: {num_hrv_features}ê°œ")
    if num_hrv_features != 39:
        raise HTTPException(
            status_code=500, 
            detail=f"HRV íŠ¹ì§• ì°¨ì› ë¶ˆì¼ì¹˜: {num_hrv_features}ê°œ (ê¸°ëŒ€ê°’: 39ê°œ)"
        )

    # --- 6. AI ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰ ë° DB ì €ì¥ (1ë¶„ ë‹¨ìœ„) ---
    print(f"[{session_id}] ğŸ¤– Step 6: AI ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰ ì‹œì‘ (1ë¶„ ë‹¨ìœ„)")
    try:
        print(f"[{session_id}] ğŸ“¦ PT íŒŒì¼ ìƒì„± ì¤‘...")
        pt_path = make_shard_and_pt(session_id, base_dir=base_dir, shard_size=150)
        if not (pt_path and os.path.exists(pt_path)):
            raise FileNotFoundError("PT íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print(f"[{session_id}] âœ… PT íŒŒì¼ ìƒì„± ì™„ë£Œ: {os.path.basename(pt_path)}")
        
        # ëª¨ë¸ ë¡œë“œ
        print(f"[{session_id}] ğŸ§  AI ëª¨ë¸ ë¡œë“œ ì¤‘...")
        edge_index_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../ml/edge_index_core.pt'))
        edge_index = torch.load(edge_index_path, map_location='cpu')
        model_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../ml/best_model.pt'))
        model = MultimodalFatigueModel(num_classes=5)
        checkpoint = torch.load(model_path, map_location='cpu')
        model.load_state_dict(checkpoint.get('model', checkpoint))
        model.eval()
        print(f"[{session_id}] âœ… AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # 2ë¶„ ë‹¨ìœ„ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰ (HRV ë°ì´í„°ì™€ ë™ê¸°í™”)
        # SEQ_LEN=12 shards Ã— 150 frames/shard Ã— (1/30) sec/frame = 60ì´ˆ = 1ë¶„
        # 2ë¶„ = 24 shards
        SEQ_LEN = 24  # 2ë¶„ì— í•´ë‹¹í•˜ëŠ” ìœˆë„ìš° ê°œìˆ˜
        STRIDE = 24   # 2ë¶„ì”© ì´ë™ (2ë¶„ = 24 shards)
        
        print(f"[{session_id}] ğŸ“Š ë°ì´í„°ì…‹ ìƒì„± ì¤‘ (SEQ_LEN={SEQ_LEN}, STRIDE={STRIDE})...")
        dataset = SessionSequenceDataset(session_dir, seq_len=SEQ_LEN, stride=STRIDE)
        if len(dataset) == 0:
            raise ValueError("2ë¶„ ì´ìƒ ì‹œì²­í•˜ì§€ ì•Šì•„ ë¶„ì„ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
        print(f"[{session_id}] âœ… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ (ì´ {len(dataset)}ê°œ ì‹œí€€ìŠ¤)")
        
        # HRV ë°ì´í„° ê°œìˆ˜ í™•ì¸ (2ë¶„ë§ˆë‹¤ 1ê°œ)
        num_hrv_segments = len(df_wearable)
        
        # ëœë“œë§ˆí¬ ë°ì´í„°ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” 2ë¶„ ë‹¨ìœ„ ì˜ˆì¸¡ ê°œìˆ˜
        num_landmark_2min_segments = len(dataset)
        
        # ì‹¤ì œ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ê°œìˆ˜ëŠ” ëœë“œë§ˆí¬ ë°ì´í„°ì™€ HRV ë°ì´í„° ì¤‘ ì‘ì€ ê°’
        num_predictions = min(num_landmark_2min_segments, num_hrv_segments)
        
        print(f"[{session_id}] ğŸ“ˆ ì˜ˆì¸¡ ì •ë³´: HRV ì„¸ê·¸ë¨¼íŠ¸={num_hrv_segments}, ëœë“œë§ˆí¬ ì„¸ê·¸ë¨¼íŠ¸={num_landmark_2min_segments} (ëª¨ë‘ 2ë¶„ ë‹¨ìœ„)")
        print(f"[{session_id}] ğŸ¯ ì´ {num_predictions}ê°œì˜ 2ë¶„ ë‹¨ìœ„ ì„¸ê·¸ë¨¼íŠ¸ ì˜ˆì¸¡ ì‹œì‘")
        
        if num_predictions == 0:
            raise ValueError("ì˜ˆì¸¡ ê°€ëŠ¥í•œ 2ë¶„ ë‹¨ìœ„ ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        all_preds = []
        with torch.no_grad():
            for idx in range(num_predictions):
                print(f"[{session_id}] ğŸ”® ì˜ˆì¸¡ ì¤‘... [{idx+1}/{num_predictions}] (ì‹œê°„: {idx*2}~{(idx+1)*2}ë¶„)")
                
                # ëœë“œë§ˆí¬ ë°ì´í„° (2ë¶„ ë‹¨ìœ„)
                face, _, _ = dataset[idx]
                face = face.unsqueeze(0)  # [1, 24, 150, 478, 3]
                
                # HRV ë°ì´í„° (2ë¶„ ë‹¨ìœ„, 1:1 ë§¤ì¹­)
                hrv_row = df_wearable.iloc[idx]
                
                # HRV íŠ¹ì§• ë²¡í„° ìƒì„± (timestamp ì œì™¸í•œ 39ê°œ íŠ¹ì§•)
                feature_cols = [col for col in df_wearable.columns if col != 'timestamp']
                hrv_vector = hrv_row[feature_cols].values.astype(float).tolist()
                
                # ì°¨ì› ê²€ì¦
                if len(hrv_vector) != 39:
                    raise ValueError(f"HRV íŠ¹ì§• ì°¨ì› ì˜¤ë¥˜: {len(hrv_vector)}ê°œ (ê¸°ëŒ€ê°’: 39ê°œ)")
                
                wear = torch.tensor(hrv_vector, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # [1, 1, 39]
                # 24ê°œ ìœˆë„ìš°ì— ë™ì¼í•œ HRV ë°ì´í„° ë³µì œ
                wear = wear.repeat(1, 24, 1)  # [1, 24, 39]
                
                pred, aux = model(face, wear, edge_index)
                drowsiness_score = float(pred.item())
                all_preds.append(drowsiness_score)
                print(f"[{session_id}] ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼: ì¡¸ìŒ ì ìˆ˜ = {drowsiness_score:.4f}")
                
                # DBì— ì €ì¥ (timestampëŠ” 0ë¶€í„° ì‹œì‘, 2ë¶„ ë‹¨ìœ„)
                drowsiness_record = DrowsinessLevel(
                    video_id=video_id,
                    student_uid=student_uid,
                    timestamp=idx * 2,  # 0 = 0~2ë¶„, 2 = 2~4ë¶„, 4 = 4~6ë¶„, ...
                    drowsiness_score=drowsiness_score
                )
                db_session.add(drowsiness_record)
        
        print(f"[{session_id}] ğŸ’¾ DBì— ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì¤‘...")
        db_session.commit()
        print(f"[{session_id}] âœ… DB ì €ì¥ ì™„ë£Œ (ì´ {len(all_preds)}ê°œ ë ˆì½”ë“œ)")
        
    except FileNotFoundError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")

    if not all_preds:
        raise HTTPException(status_code=400, detail="ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    print(f"[{session_id}] ğŸ‰ ì¡¸ìŒ íƒì§€ ë¶„ì„ ì™„ë£Œ!")
    print(f"[{session_id}] ğŸ“Š ìµœì¢… ê²°ê³¼: ì´ {len(all_preds)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ (2ë¶„ ë‹¨ìœ„), ë§ˆì§€ë§‰ ì¡¸ìŒ ì ìˆ˜ = {all_preds[-1]:.4f}")
    
    prediction = DrowsinessPrediction(
        session_id=session_id,
        drowsiness_level=all_preds[-1],
        confidence=1.0,
        details={"total_segments": len(all_preds), "all_preds": all_preds}
    )
    return DrowsinessFinishResponse(
        session_id=session_id,
        prediction=prediction,
        message=f"ì¡¸ìŒ ì˜ˆì¸¡ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ {len(all_preds)}ê°œì˜ 2ë¶„ ë‹¨ìœ„ ì„¸ê·¸ë¨¼íŠ¸ê°€ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤."
    )


# =========================
# í…ŒìŠ¤íŠ¸ìš© API (ì‹ ê·œ ì¶”ê°€)
# =========================

@router.post("/drowsiness/testFinish", summary="[í…ŒìŠ¤íŠ¸ìš©] Firebase PPG ë°ì´í„° ë¡œì»¬ ì €ì¥")
def test_finish_drowsiness_detection(
        req: DrowsinessFinishRequest,
):
    """
    [í…ŒìŠ¤íŠ¸ ì „ìš©] Session IDë¥¼ ë°›ì•„ Firebaseì—ì„œ PPG ë°ì´í„°ë§Œ ê°€ì ¸ì™€
    ì„œë²„ ë¡œì»¬ ê²½ë¡œ(drowsiness_data/{session_id}/ppg_data.csv)ì— ì €ì¥í•©ë‹ˆë‹¤.
    ì¸ì¦, ì„¸ì…˜ ì¢…ë£Œ, ML ë¶„ì„ ë“±ì˜ ê³¼ì •ì€ ìƒëµë©ë‹ˆë‹¤.
    """
    session_id = req.session_id

    try:
        from firebase_admin import db
        session_ref = db.reference(f"{session_id}")

        # ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ”ì§€ ê°„ë‹¨íˆ í™•ì¸
        if not session_ref.get():
            raise HTTPException(status_code=404, detail=f"ì„¸ì…˜ ID '{session_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Firebase ì„¸ì…˜ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../drowsiness_data'))
    session_dir = os.path.join(base_dir, session_id)

    try:
        ppg_data_ref = session_ref.child("PPG_Data")
        ppg_data = ppg_data_ref.get()

        if ppg_data:
            ppg_list = [v for k, v in ppg_data.items()]
            df = pd.DataFrame(ppg_list)
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df = df.sort_values(by='timestamp').reset_index(drop=True)
            os.makedirs(session_dir, exist_ok=True)
            ppg_csv_path = os.path.join(session_dir, 'ppg_data.csv')
            df.to_csv(ppg_csv_path, index=False)
            message = f"PPG ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ '{ppg_csv_path}' ê²½ë¡œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
        else:
            message = f"ì„¸ì…˜ {session_id}ì— ëŒ€í•œ PPG ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í´ë”ë§Œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
            os.makedirs(session_dir, exist_ok=True)  # ë°ì´í„°ê°€ ì—†ì–´ë„ í´ë”ëŠ” ìƒì„±

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Firebase PPG ë°ì´í„° ì²˜ë¦¬ ë° ì €ì¥ ì‹¤íŒ¨: {e}")

    return {"message": message, "session_id": session_id}

